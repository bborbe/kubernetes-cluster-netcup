#cloud-config
ssh_authorized_keys:
 - ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCOw/yh7+j3ygZp2aZRdZDWUh0Dkj5N9/USdiLSoS+0CHJta+mtSxxmI/yv1nOk7xnuA6qtjpxdMlWn5obtC9xyS6T++tlTK9gaPwU7a/PObtoZdfQ7znAJDpX0IPI06/OH1tFE9kEutHQPzhCwRaIQ402BHIrUMWzzP7Ige8Oa0HwXH4sHUG5h/V/svzi9T0CKJjF8dTx4iUfKX959hT8wQnKYPULewkNBFv6pNfWIr8EzvIEQcPmmm3tP+dQPKg5QKVi6jPdRla+t5HXfhXu0W3WCDa2s0VGmJjBdMMowr5MLNYI79MKziSV1w1IWL17Z58Lop0zEHqP7Ba0Aooqd
hostname: kubernetes
coreos:
  update:
    reboot-strategy: reboot
  units:
    - name: systemd-sysctl.service
      command: restart
    - name: iptables-restore.service
      enable: true
    - name: 10-ens3.network
      content: |
        [Match]
        MACAddress=ea:96:69:06:f5:7d
        [Network]
        Address=185.170.112.48/22
        Gateway=185.170.112.1
        DNS=8.8.8.8
    - name: rpc-statd.service
      command: start
      enable: true
    - name: etcd-member.service
      drop-ins:
      - name: 50-network-config.conf
        content: |
          [Service]
          Environment="ETCD_NAME=kubernetes"
          Environment="ETCD_INITIAL_CLUSTER=kubernetes=http://185.170.112.48:2380"
          Environment="ETCD_INITIAL_CLUSTER_TOKEN=cluster-netcup"
          Environment="ETCD_LISTEN_CLIENT_URLS=http://0.0.0.0:2379,http://0.0.0.0:4001"
          Environment="ETCD_INITIAL_CLUSTER_STATE=new"
          Environment="ETCD_ADVERTISE_CLIENT_URLS=http://185.170.112.48:2379"
          Environment="ETCD_INITIAL_ADVERTISE_PEER_URLS=http://185.170.112.48:2380"
          Environment="ETCD_LISTEN_PEER_URLS=http://0.0.0.0:2380"
      command: start
    - name: rpc-mountd.service
      command: start
    - name: nfsd.service
      command: start
    - name:  systemd-networkd.service
      command: restart
    - name: flanneld.service
      command: start
      drop-ins:
        - name: 50-network-config.conf
          content: |
            [Service]
            ExecStartPre=/usr/bin/etcdctl set /coreos.com/network/config '{ "Network": "10.102.0.0/16", "Backend":{"Type":"vxlan"} }'
    - name: delete-kubernetes-manifests.service
      command: start
      content: |
        [Unit]
        Description=Delete Kubernetes Manifest Files
        [Service]
        Type=oneshot
        ExecStart=-/bin/bash -c 'echo "Delete Kubernetes Manifest Files";rm -f /etc/kubernetes/manifests/kube-controller-manager.yaml /etc/kubernetes/manifests/kube-scheduler.yaml'
    - name: docker.service
      command: start
      drop-ins:
        - name: 40-flannel.conf
          content: |
            [Unit]
            Requires=flanneld.service
            After=flanneld.service
        - name: 20-wait-iptables.conf
          content: |
            [Unit]
            After=iptables-restore.service
            Requires=iptables-restore.service
    - name: docker-cleanup.service
      content: |
        [Unit]
        Description=Docker Cleanup
        Requires=docker.service
        After=docker.service
        [Service]
        Type=oneshot
        ExecStart=-/bin/bash -c '/usr/bin/docker rm -v $(/usr/bin/docker ps -a -q -f status=exited)'
        ExecStart=-/bin/bash -c '/usr/bin/docker rmi $(/usr/bin/docker images -f dangling=true -q)'
    - name: docker-cleanup.timer
      command: start
      content: |
        [Unit]
        Description=Docker Cleanup every 4 hours
        [Timer]
        Unit=docker-cleanup.service
        OnCalendar=*-*-* 0/4:00:00
        [Install]
        WantedBy=multi-user.target
    - name: kubelet.service
      command: start
      content: |
        [Unit]
        Description=Kubelet
        Requires=docker.service
        After=docker.service
        [Service]
        Restart=always
        RestartSec=20s
        EnvironmentFile=/etc/environment
        TimeoutStartSec=0
        ExecStart=/usr/bin/docker run \
          --memory=2048m \
          --volume=/:/rootfs:ro \
          --volume=/sys:/sys:ro \
          --volume=/var/log/:/var/log:rw \
          --volume=/var/lib/docker/:/var/lib/docker:rw \
          --volume=/var/lib/kubelet/:/var/lib/kubelet:rw,rslave \
          --volume=/run:/run:rw \
          --volume=/var/run:/var/run:rw \
          --volume=/etc/kubernetes:/etc/kubernetes \
          --volume=/srv/kubernetes:/srv/kubernetes \
          --net=host \
          --privileged=true \
          --pid=host \
          gcr.io/google_containers/hyperkube-amd64:v1.11.2 \
          /hyperkube kubelet \
            --containerized \
            --register-node=true \
            --allow-privileged=true \
            --pod-manifest-path=/etc/kubernetes/manifests \
            --hostname-override=185.170.112.48 \
            --cluster-dns=10.103.0.10 \
            --cluster-domain=cluster.local \
            --kubeconfig=/etc/kubernetes/node-kubeconfig.yaml \
            --node-labels=etcd=true,nfsd=true,worker=true,master=true \
            --v=0
        [Install]
        WantedBy=multi-user.target
    - name: kube-system-namespace.service
      command: start
      content: |
        [Unit]
        Description=Create Kube-System Namespace
        Requires=kubelet.service
        After=kubelet.service
        [Service]
        Restart=on-failure
        RestartSec=60s
        ExecStart=/bin/bash -c '\
          echo "try create namepsace kube-system"; \
          while true; do \
            curl -sf "http://127.0.0.1:8080/version"; \
            if [ $? -eq 0 ]; then \
              echo "api up. create namepsace kube-system"; \
              curl -XPOST -H Content-Type: application/json -d\'{"apiVersion":"v1","kind":"Namespace","metadata":{"name":"kube-system"}}\' "http://127.0.0.1:8080/api/v1/namespaces"; \
              echo "namepsace kube-system created"; \
              exit 0; \
            else \
              echo "api down. sleep."; \
              sleep 20; \
            fi; \
          done'
        [Install]
        WantedBy=multi-user.target
write_files:
  - path: /var/lib/iptables/rules-save
    permissions: 0644
    owner: root:root
    content: |
      *mangle
      :PREROUTING ACCEPT [0:0]
      :INPUT ACCEPT [0:0]
      :FORWARD ACCEPT [0:0]
      :OUTPUT ACCEPT [0:0]
      :POSTROUTING ACCEPT [0:0]
      COMMIT
      *nat
      :PREROUTING ACCEPT [0:0]
      :INPUT ACCEPT [0:0]
      :OUTPUT ACCEPT [0:0]
      :POSTROUTING ACCEPT [0:0]
      -A POSTROUTING -s 10.0.0.0/8 -o eth0 -j MASQUERADE
      -A POSTROUTING -s 172.16.0.0/12 -o eth0 -j MASQUERADE
      -A POSTROUTING -s 192.168.0.0/16 -o eth0 -j MASQUERADE
      COMMIT
      *filter
      :INPUT DROP [0:0]
      :FORWARD DROP [0:0]
      :OUTPUT DROP [0:0]
      -A INPUT -i lo -j ACCEPT
      -A OUTPUT -o lo -j ACCEPT
      -A OUTPUT -m state --state NEW,RELATED,ESTABLISHED -j ACCEPT
      -A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT
      -A INPUT -p icmp -m icmp --icmp-type 8 -j ACCEPT
      -A INPUT -p icmp -m icmp --icmp-type 11 -j ACCEPT
      -A INPUT -p tcp -m state --state NEW -m tcp --dport 22 -j ACCEPT
      -A INPUT -p tcp -m state --state NEW -m tcp --dport 25 -j ACCEPT
      -A INPUT -p tcp -m state --state NEW -m tcp --dport 53 -j ACCEPT
      -A INPUT -p udp -m state --state NEW -m udp --dport 53 -j ACCEPT
      -A INPUT -p tcp -m state --state NEW -m tcp --dport 80 -j ACCEPT
      -A INPUT -p tcp -m state --state NEW -m tcp --dport 143 -j ACCEPT
      -A INPUT -p tcp -m state --state NEW -m tcp --dport 443 -j ACCEPT
      -A INPUT -p tcp -m state --state NEW -m tcp --dport 465 -j ACCEPT
      -A INPUT -p tcp -m state --state NEW -m tcp --dport 587 -j ACCEPT
      -A INPUT -p tcp -m state --state NEW -m tcp --dport 993 -j ACCEPT
      -A INPUT -p tcp -m state --state NEW -m tcp --dport 2222 -j ACCEPT
      -A INPUT -p tcp -m state --state NEW -m tcp --dport 3128 -j ACCEPT
      -A INPUT -p tcp -m state --state NEW -m tcp --dport 6443 -j ACCEPT
      -A INPUT -p tcp -m state --state NEW -m tcp --dport 64738 -j ACCEPT
      -A INPUT -i docker0 -p tcp -m state --state NEW -m tcp --dport 10255 -j ACCEPT
      COMMIT
  - path: /etc/sysctl.d/vm_max_map_count.conf
    content: |
      vm.max_map_count=262144
  - path: /etc/environment
    permissions: 0644
    content: |
      COREOS_PUBLIC_IPV4=185.170.112.48
      COREOS_PRIVATE_IPV4=185.170.112.48
  - path: /run/flannel/options.env
    permissions: 0644
    content: |
      FLANNELD_IFACE=185.170.112.48
      FLANNELD_ETCD_ENDPOINTS=http://185.170.112.48:2379
  - path: /root/.toolboxrc
    owner: core
    content: |
      TOOLBOX_DOCKER_IMAGE=bborbe/toolbox
      TOOLBOX_DOCKER_TAG=latest
      TOOLBOX_USER=root
  - path: /home/core/.toolboxrc
    owner: core
    content: |
      TOOLBOX_DOCKER_IMAGE=bborbe/toolbox
      TOOLBOX_DOCKER_TAG=latest
      TOOLBOX_USER=root
  - path: /etc/exports
    permissions: 0644
    content: |
      /data/ 185.170.112.0/22(rw,async,no_subtree_check,no_root_squash,fsid=0)
  - path: /etc/kubernetes/manifests/kube-apiserver.yaml
    permissions: 0644
    content: |
      apiVersion: v1
      kind: Pod
      metadata:
        name: kube-apiserver
        namespace: kube-system
      spec:
        hostNetwork: true
        containers:
        - name: kube-apiserver
          image: gcr.io/google_containers/hyperkube-amd64:v1.11.2
          command:
          - /hyperkube
          - apiserver
          - --bind-address=0.0.0.0
          - --etcd-servers=http://185.170.112.48:2379
          - --storage-backend=etcd3
          - --allow-privileged=true
          - --service-cluster-ip-range=10.103.0.0/16
          - --secure-port=6443
          - --advertise-address=185.170.112.48
          - --admission-control=NamespaceLifecycle,NamespaceExists,LimitRanger,SecurityContextDeny,ServiceAccount,DefaultStorageClass,ResourceQuota
          - --tls-cert-file=/etc/kubernetes/ssl/node.pem
          - --tls-private-key-file=/etc/kubernetes/ssl/node-key.pem
          - --client-ca-file=/etc/kubernetes/ssl/ca.pem
          - --service-account-key-file=/etc/kubernetes/ssl/node-key.pem
          - --runtime-config=extensions/v1beta1/networkpolicies=true,batch/v2alpha1=true
          - --anonymous-auth=false
          - --authorization-mode=RBAC
          livenessProbe:
            httpGet:
              host: 127.0.0.1
              port: 8080
              path: /healthz
            initialDelaySeconds: 15
            timeoutSeconds: 15
          ports:
          - containerPort: 6443
            hostPort: 6443
            name: https
          - containerPort: 8080
            hostPort: 8080
            name: local
          volumeMounts:
          - mountPath: /etc/kubernetes/ssl
            name: ssl-certs-kubernetes
            readOnly: true
          - mountPath: /etc/ssl/certs
            name: ssl-certs-host
            readOnly: true
        volumes:
        - hostPath:
            path: /etc/kubernetes/ssl
          name: ssl-certs-kubernetes
        - hostPath:
            path: /usr/share/ca-certificates
          name: ssl-certs-host
  - path: /etc/kubernetes/manifests/kube-podmaster.yaml
    permissions: 0644
    content: |
      apiVersion: v1
      kind: Pod
      metadata:
        name: kube-podmaster
        namespace: kube-system
      spec:
        hostNetwork: true
        containers:
        - name: controller-manager-elector
          image: gcr.io/google_containers/podmaster:1.1
          command:
          - /podmaster
          - --etcd-servers=http://185.170.112.48:2379
          - --key=controller
          - --whoami=185.170.112.48
          - --source-file=/src/manifests/kube-controller-manager.yaml
          - --dest-file=/dst/manifests/kube-controller-manager.yaml
          terminationMessagePath: /dev/termination-log
          volumeMounts:
          - mountPath: /src/manifests
            name: manifest-src
            readOnly: true
          - mountPath: /dst/manifests
            name: manifest-dst
        - name: scheduler-elector
          image: gcr.io/google_containers/podmaster:1.1
          command:
          - /podmaster
          - --etcd-servers=http://185.170.112.48:2379
          - --key=scheduler
          - --whoami=185.170.112.48
          - --source-file=/src/manifests/kube-scheduler.yaml
          - --dest-file=/dst/manifests/kube-scheduler.yaml
          volumeMounts:
          - mountPath: /src/manifests
            name: manifest-src
            readOnly: true
          - mountPath: /dst/manifests
            name: manifest-dst
        volumes:
        - hostPath:
            path: /srv/kubernetes/manifests
          name: manifest-src
        - hostPath:
            path: /etc/kubernetes/manifests
          name: manifest-dst
  - path: /etc/kubernetes/node-kubeconfig.yaml
    permissions: 0644
    content: |
      apiVersion: v1
      kind: Config
      clusters:
      - name: local
        cluster:
          certificate-authority: /etc/kubernetes/ssl/ca.pem
          server: http://127.0.0.1:8080
      users:
      - name: kubelet
        user:
          client-certificate: /etc/kubernetes/ssl/node.pem
          client-key: /etc/kubernetes/ssl/node-key.pem
      contexts:
      - context:
          cluster: local
          user: kubelet
        name: kubelet-context
      current-context: kubelet-context
  - path: /etc/kubernetes/manifests/kube-proxy.yaml
    permissions: 0644
    content: |
      apiVersion: v1
      kind: Pod
      metadata:
        name: kube-proxy
        namespace: kube-system
      spec:
        hostNetwork: true
        containers:
        - name: kube-proxy
          image: gcr.io/google_containers/hyperkube-amd64:v1.11.2
          command:
          - /hyperkube
          - proxy
          - --master=http://127.0.0.1:8080
          - --proxy-mode=iptables
          securityContext:
            privileged: true
          volumeMounts:
            - mountPath: /etc/ssl/certs
              name: ssl-certs-host
              readOnly: true
        volumes:
          - name: ssl-certs-host
            hostPath:
              path: "/usr/share/ca-certificates"
  - path: /srv/kubernetes/manifests/kube-scheduler.yaml
    permissions: 0644
    content: |
      apiVersion: v1
      kind: Pod
      metadata:
        name: kube-scheduler
        namespace: kube-system
      spec:
        hostNetwork: true
        containers:
        - name: kube-scheduler
          image: gcr.io/google_containers/hyperkube-amd64:v1.11.2
          command:
          - /hyperkube
          - scheduler
          - --master=http://127.0.0.1:8080
          livenessProbe:
            httpGet:
              host: 127.0.0.1
              path: /healthz
              port: 10251
            initialDelaySeconds: 15
            timeoutSeconds: 1
  - path: /srv/kubernetes/manifests/kube-controller-manager.yaml
    permissions: 0644
    content: |
      apiVersion: v1
      kind: Pod
      metadata:
        name: kube-controller-manager
        namespace: kube-system
      spec:
        hostNetwork: true
        containers:
        - name: kube-controller-manager
          image: gcr.io/google_containers/hyperkube-amd64:v1.11.2
          command:
          - /hyperkube
          - controller-manager
          - --master=http://127.0.0.1:8080
          - --service-account-private-key-file=/etc/kubernetes/ssl/node-key.pem
          - --root-ca-file=/etc/kubernetes/ssl/ca.pem
          livenessProbe:
            httpGet:
              host: 127.0.0.1
              path: /healthz
              port: 10252
            initialDelaySeconds: 15
            timeoutSeconds: 1
          volumeMounts:
          - mountPath: /etc/kubernetes/ssl
            name: ssl-certs-kubernetes
            readOnly: true
          - mountPath: /etc/ssl/certs
            name: ssl-certs-host
            readOnly: true
        volumes:
        - name: ssl-certs-kubernetes 
          hostPath:
            path: /etc/kubernetes/ssl
        - name: ssl-certs-host 
          hostPath:
            path: /usr/share/ca-certificates
